{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access cloud data examples tutorial\n",
    " \n",
    "### Credits: Tutorial development\n",
    "* [Dr. Chelle Gentemann](mailto:gentemann@faralloninstitute.org)    - Farallon Institute, USA\n",
    "* [Dr. Ryan Abernathey](mailto:rpa@ldeo.columbia.edu) - LDEO\n",
    "* [Henri Drake](mailto:hdrake@mit.edu) - MIT \n",
    "\n",
    "### Data on the cloud can be stored in many different formats.  \n",
    "\n",
    "### Here we will demonstrate some ways to get at the CMIP6, MUR SST, and AVISO data. \n",
    "\n",
    "### These are BIG datasets that you can analyze without downloading now on the cloud. \n",
    "\n",
    "\n",
    "First start by importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import intake\n",
    "\n",
    "warnings.simplefilter('ignore') # filter some warning messages\n",
    "xr.set_options(display_style=\"html\")  #display dataset nicely \n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "%config InlineBackend.figure_format = 'retina' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a cluster, the key to reading effectively on Cloud\n",
    "\n",
    "- This will set up a cluster for your analysis and give you a path that you can paste into the top of the Dask dashboard to visualize parts of your cluster.  \n",
    "- You don't need to paste the link below into the Dask dashboard for this to work, only to see workers working.\n",
    "- Try 40 workers to start (during the tutorial) but you can increase to speed things up later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_kubernetes import KubeCluster\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = KubeCluster()\n",
    "\n",
    "client = Client(cluster)\n",
    "\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ☝️ Don’t forget to click the link above or copy it to the Dask dashboard on the left to view the scheduler dashboard! **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in AVISO sea surface height data using intake from the Pangeo datastore on Google Cloud\n",
    "\n",
    "### Here we use the ``intake`` library to access the Pangeo datastore on google cloud\n",
    "\n",
    "This call reads the metadata into memory but in a 'lazy' way.  You haven't actually touched the data yet which is why it is so fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cat_pangeo = intake.Catalog(\"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/ocean.yaml\")\n",
    "\n",
    "ds_aviso = cat_pangeo[\"sea_surface_height\"].to_dask()\n",
    "\n",
    "ds_aviso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data\n",
    "\n",
    "We are looking at the sea level anomaly in this plot and use ``.sel`` to select day to look at.  One of the nice features of ``xarray`` is that it allows you to use coordinates to select data in a way that makes it easy to understand later what you were trying to do.\n",
    "\n",
    "An overview of ``xarray`` plotting is [here](http://xarray.pydata.org/en/stable/plotting.html). Here we use [.plot](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.plot.html) to create a figure of the data with several arguments to specify details in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_aviso['sla'].sel(time='2015-01-01').plot(vmin=-2,vmax=2,cmap='seismic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a timeseries\n",
    "\n",
    "Xarray has a lot of nice build-in features, such as [.resampe](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.resample.html#xarray-dataset-resample) which can upsample or downsample data and [.mean](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.mean.html#xarray-dataarray-mean). Here we use these to calculate monthly means.  We then take the monthly means and use ``.mean`` again, with the coordinates 'latitude' and 'longitude' as arguments to create a timeseries of the monthly mean.  Finally, we plot the data and label the axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sla_monthly = ds_aviso['sla'].resample(time='1MS').mean()\n",
    "\n",
    "sla_monthly_timeseries = sla_monthly.mean({'latitude','longitude'})\n",
    "\n",
    "sla_monthly_timeseries.plot(label='Full data')\n",
    "\n",
    "plt.ylabel('Sea Level Anomaly [m]')\n",
    "plt.title('Global Mean Sea Level')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CMIP6 data from Google Cloud using intake\n",
    "\n",
    "The CMIP6 data is a huge collection of different experiements.  Access to these data uses the [intake-esm](https://github.com/NCAR/intake-esm) library which you then use the catalog to select specific variables, experiments, or activities.  There are some great tutorials [here](https://github.com/hdrake/cmip6-temperature-demo/) and [here](https://github.com/pangeo-data/pangeo-cmip6-examples/).\n",
    "\n",
    "More information on CMIP6 is [here](https://www.earthsystemcog.org/projects/wip/CMIP6DataRequest) and variable names [here](https://docs.google.com/document/d/1h0r8RZr_f3-8egBMMh7aqLwy3snpD6_MrDz1q8n5XUk/edit)\n",
    "\n",
    "A nice introduction is [here](https://towardsdatascience.com/a-quick-introduction-to-cmip6-e017127a49d3)\n",
    "\n",
    "The Pangeo catalog listing is [here](https://pangeo-data.github.io/pangeo-datastore/cmip6_pangeo.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "col = intake.open_esm_datastore(\"https://raw.githubusercontent.com/NCAR/intake-esm-datastore/master/catalogs/pangeo-cmip6.json\")\n",
    "\n",
    "col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search the collection for historical, monthly, air temperature, for one realization\n",
    "\n",
    "You can use the variable names (link given above) to search for different parameters, change the table id from atmospheric monthly to ocean monthly, 3hrly data etc.  More information on what you can search for is in this [tutorial](https://intake-esm.readthedocs.io/en/latest/notebooks/tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cmip = col.search(experiment_id=['ssp585','historical'],  # pick the `historical` forcing experiment\n",
    "                 table_id='Amon',             # choose to look at atmospheric variables (A) saved at monthly resolution (mon)\n",
    "                 variable_id='tas',           # choose to look at near-surface air temperature (tas) as our variable\n",
    "                 member_id = 'r1i1p1f1')      # arbitrarily pick one realization for each model (i.e. just one set of initial conditions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data catalog into a dictionary of xarray datasets\n",
    "\n",
    "dset_dict is a dictionary of xarray.Datasets where its keys refer to compatible groups.\n",
    "\n",
    "We then set the time period we are interested in and create a new dictionary containing the variable of interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_dict = cat_cmip.to_dataset_dict(zarr_kwargs={'consolidated': True, 'decode_times': False})\n",
    "\n",
    "time_slice = slice('1850','2015') # specific years that bracket our period of interest\n",
    "\n",
    "ds_dict = {}\n",
    "\n",
    "for name, ds in dset_dict.items():\n",
    "    # rename spatial dimensions if necessary\n",
    "    if ('longitude' in ds.dims) and ('latitude' in ds.dims):\n",
    "        ds = ds.rename({'longitude':'lon', 'latitude': 'lat'}) \n",
    "        \n",
    "    ds = xr.decode_cf(ds) # temporary hack, not sure why I need this but has to do with calendar-aware metadata on the time variable\n",
    "    ds = ds.sel(time=time_slice) # subset the data for the time period of interest\n",
    "    \n",
    "    # drop redundant coordinates \n",
    "    for coord in ds.coords:\n",
    "        if coord not in ['lat','lon','time']:\n",
    "            ds = ds.drop(coord)\n",
    "    \n",
    "    # Add near-surface air temperature to dictionary\n",
    "    ds_dict[name] = ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at how air temperatures have changed \n",
    "\n",
    "Look at the data we have, and create means for more recent and historical data to examine how air temperatures have changed.  The last step here is to set a data attribute so that when it is plotted the labels are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cmip = ds_dict[list(ds_dict.keys())[0]]\n",
    "\n",
    "now = ds_cmip.sel(time=slice('2000-01-01','2015-12-31')).mean('time')\n",
    "\n",
    "then = ds_cmip.sel(time=slice('1850-01-01','1950-12-31')).mean('time')\n",
    "\n",
    "temperature_change=(now-then)['tas']\n",
    "\n",
    "temperature_change.attrs['long_name']='Change in air temperature (K)'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the change in temperature\n",
    "\n",
    "Here we use the excellent [cartopy](https://scitools.org.uk/cartopy/docs/latest/) library to plot our data on a projection and add both coastlines and borders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ortho = ccrs.Orthographic(-90, 20)           # define target coordinate frame\n",
    "geo = ccrs.PlateCarree()                     # define origin coordinate frame\n",
    "\n",
    "plt.figure(figsize=(9,7))                    #set the figure size\n",
    "ax = plt.subplot(1, 1, 1, projection=ortho)  #create the axis for plotting\n",
    "\n",
    "q = temperature_change.plot(ax=ax, \n",
    "                            transform = geo, \n",
    "                            cmap='OrRd', \n",
    "                            vmin=0, \n",
    "                            vmax=3) # plot a colormap in transformed coordinates\n",
    "\n",
    "ax.add_feature(cartopy.feature.COASTLINE)\n",
    "\n",
    "ax.add_feature(cartopy.feature.BORDERS, linestyle='-')\n",
    "\n",
    "plt.title('Global Warming Air Temp',fontsize=16, ha='center');\n",
    "\n",
    "#plt.savefig('./../../airtemp_warming_patterns.png',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read MUR SST from AWS public dataset program on an s3 bucket.  This Pangeo binder is running on Google Cloud and data access takes longer because the data is on AWS.  \n",
    "\n",
    "This code is an example of how to read from a s3 bucket.  Right now (2/14/2020) this takes ~2 min on the google cloud, in part because of how we chunked the data in time.  We should have the data re-chunked in time by 3/1/2020 and then it should read in less than 30 sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "file_location = 's3://mur-sst/zarr'\n",
    "\n",
    "ds_sst = xr.open_zarr(fsspec.get_mapper(file_location, anon=True),consolidated=True)\n",
    "\n",
    "ds_sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read entire 18 years of data at 1 point.\n",
    "\n",
    "Select the ``analysed_sst`` variable at a specific latitute and longitude and load the data into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sst_timeseries = ds_sst['analysed_sst'].sel(time=slice('2010-01-01','2020-01-01'),\n",
    "                                            lat=47,\n",
    "                                            lon=-145,\n",
    "                                            method='nearest').load()\n",
    "\n",
    "sst_timeseries.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The anomaly is more interesting...  \n",
    "\n",
    "#### Use [.groupby](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.groupby.html#xarray-dataarray-groupby) to calculate the climatology and [.resample](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.resample.html#xarray-dataset-resample) to then average it into 1-month bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_climatology = sst_timeseries.groupby('time.dayofyear').mean()\n",
    "\n",
    "sst_anomaly = sst_timeseries.groupby('time.dayofyear')-sst_climatology\n",
    "\n",
    "sst_anomaly_monthly = sst_anomaly.resample(time='1MS').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_anomaly.plot()\n",
    "\n",
    "sst_anomaly_monthly.plot()\n",
    "\n",
    "plt.axhline(linewidth=2,color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
