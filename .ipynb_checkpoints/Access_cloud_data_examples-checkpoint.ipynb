{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access cloud data examples tutorial\n",
    " \n",
    "Credits: Tutorial development\n",
    "* [Dr. Chelle Gentemann](mailto:gentemann@faralloninstitute.org)    - Farallon Institute, USA\n",
    "* [Dr. Ryan Abernathey](mailto:rpa@ldeo.columbia.edu) - LDEO\n",
    "* [Henri Drake](mailto:hdrake@mit.edu) - MIT \n",
    "\n",
    "Data on the cloud can be stored in many different formats.  Here we will demonstrate some ways to get at the CMIP6, MUR SST, and AVISO data.  \n",
    "\n",
    "\n",
    "First start by importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import intake\n",
    "\n",
    "warnings.simplefilter('ignore') # filter some warning messages\n",
    "xr.set_options(display_style=\"html\")  #display dataset nicely \n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "%config InlineBackend.figure_format = 'retina' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a cluster, the key to reading effectively on Cloud\n",
    "\n",
    "- This will set up a cluster for you and give you a path that you can paste into the top of the Dask dashboard to visualize parts of your cluster.  \n",
    "- You don't need to paste the link below into the Dask dashboard for this to work, only to see workers working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_kubernetes import KubeCluster\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = KubeCluster(n_workers=200)\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ☝️ Don’t forget to click the link above or copy it to the Dask dashboard on the left to view the scheduler dashboard! **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read MUR SST from AWS public dataset program on an s3 bucket\n",
    "\n",
    "The MUR SSTs have been reformated into a cloud optimized zarr format.  \n",
    "\n",
    "Reading the entire global, 1 km, daily, 18 years of data is as simple as pointing to the directory the files are stored in.\n",
    "\n",
    "This Pangeo binder is running on Google Cloud and will run slower for this data because it is on AWS.  There is a Pangeo binder for AWS as well, but for this tutorial we are using the Google Cloud.\n",
    "Wall time GC: 1min43sec\n",
    "Wall time AWS: 33sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "file_location = 's3://mur-sst/zarr'\n",
    "ds_sst = xr.open_zarr(fsspec.get_mapper(file_location, anon=True),consolidated=True)\n",
    "ds_sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are running the tutorial on the google cloud (so data on AWS will take a bit longer to load)  \n",
    "\n",
    "Read 1 day of data: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#sst_day = ds_sst['analysed_sst'].sel(time='2015-10-01T09').load()\n",
    "#sst_day.sel(lat=slice(20,60),lon=slice(-175,-110)).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read entire 18 years of data at 1 point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sst_timeseries = ds_sst['analysed_sst'].sel(lat=47,lon=-145,method='nearest').load()\n",
    "sst_timeseries.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The anomaly is more interesting... Use ``.groupby``to calculate the climatology and ``resample`` to then average it into 2-month bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_climatology = sst_timeseries.groupby('time.dayofyear').mean()\n",
    "sst_anomaly = sst_timeseries.groupby('time.dayofyear')-sst_climatology\n",
    "\n",
    "#now plot the data\n",
    "sst_anomaly.plot()\n",
    "sst_anomaly.resample(time='2MS').mean().plot()\n",
    "plt.axhline(linewidth=2,color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=sst_anomaly.where(sst_anomaly>=0)\n",
    "n=sst_anomaly.where(sst_anomaly<0)\n",
    "plt.bar(p.time.values,p, width=30, color='darkred',alpha=0.8, edgecolor=None,zorder=2)\n",
    "plt.bar(n.time.values,n, width=30, color='darkblue',alpha=0.8, edgecolor=None,zorder=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in AVISO sea surface height data using intake from the Pangeo datastore on Google Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cat_pangeo = intake.Catalog(\"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/ocean.yaml\")\n",
    "ds_aviso = cat_pangeo[\"sea_surface_height\"].to_dask()\n",
    "ds_aviso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_aviso['adt'].sel(time='2015-01-01').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CMIP6 data from Google Cloud using intake\n",
    "\n",
    "The CMIP6 data is a huge collection of different experiements.  Access to these data uses the intake library which you then use the catalog to select specific variables, experiments, or activities.  There are some great tutorials [here](https://github.com/hdrake/cmip6-temperature-demo/) and [here](https://github.com/pangeo-data/pangeo-cmip6-examples/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "col = intake.open_esm_datastore(\"https://raw.githubusercontent.com/NCAR/intake-esm-datastore/master/catalogs/pangeo-cmip6.json\")\n",
    "col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search the collection for historical, monthly, air temperature, for one realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cmip = col.search(experiment_id=['ssp585','historical'],  # pick the `historical` forcing experiment\n",
    "                 table_id='Amon',             # choose to look at atmospheric variables (A) saved at monthly resolution (mon)\n",
    "                 variable_id='tas',           # choose to look at near-surface air temperature (tas) as our variable\n",
    "                 member_id = 'r1i1p1f1')      # arbitrarily pick one realization for each model (i.e. just one set of initial conditions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data catalog into a dictionary of xarray datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_dict = cat_cmip.to_dataset_dict(zarr_kwargs={'consolidated': True, 'decode_times': False})\n",
    "\n",
    "time_slice = slice('1850','2015') # specific years that bracket our period of interest\n",
    "\n",
    "ds_dict = {}\n",
    "\n",
    "for name, ds in dset_dict.items():\n",
    "    # rename spatial dimensions if necessary\n",
    "    if ('longitude' in ds.dims) and ('latitude' in ds.dims):\n",
    "        ds = ds.rename({'longitude':'lon', 'latitude': 'lat'}) # some models labelled dimensions differently...\n",
    "        \n",
    "    ds = xr.decode_cf(ds) # temporary hack, not sure why I need this but has to do with calendar-aware metadata on the time variable\n",
    "    ds = ds.sel(time=time_slice) # subset the data for the time period of interest\n",
    "    \n",
    "    # drop redundant variables (like \"height: 2m\")\n",
    "    for coord in ds.coords:\n",
    "        if coord not in ['lat','lon','time']:\n",
    "            ds = ds.drop(coord)\n",
    "    \n",
    "    # Add near-surface air temperature to dictionary\n",
    "    ds_dict[name] = ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at how air temperatures have changed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cmip = ds_dict[list(ds_dict.keys())[0]]\n",
    "now = ds_cmip.sel(time=slice('1995-01-01','1999-12-31')).mean('time')\n",
    "then = ds_cmip.sel(time=slice('1850-01-01','1950-12-31')).mean('time')\n",
    "temperature_change=(now-then)['tas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the change in temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ortho = ccrs.Orthographic(-90, 20) # define target coordinate frame\n",
    "geo = ccrs.PlateCarree() # define origin coordinate frame\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "ax = plt.subplot(1, 1, 1, projection=ortho)\n",
    "\n",
    "temperature_change.attrs['long_name']='Change in air temperature (K)'\n",
    "q = temperature_change.plot(ax=ax, transform = geo, cmap='OrRd', vmin=0, vmax=2) # plot a colormap in transformed coordinates\n",
    "\n",
    "ax.add_feature(cartopy.feature.COASTLINE)\n",
    "ax.add_feature(cartopy.feature.BORDERS, linestyle='-')\n",
    "plt.title('Patterns of global warming over the Americas',fontsize=16, ha='center');\n",
    "#plt.savefig('./../../airtemp_warming_patterns.png',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
